{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/com_2/workspace/pig_dataset/test/20230504_14.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230504_18.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230504_7.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230511_1.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230511_3.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230511_6.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230518_2.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230518_7.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230622_13.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230622_16.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230622_17.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230622_20.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230706_4.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230720_14.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230720_15.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230720_16.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230727_1.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230727_13.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230727_18.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230727_19.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230810_13.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230810_14.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230810_15.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230810_16.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230810_17.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230921_15.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230921_16.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230921_17.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230921_18.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230921_19.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230921_20.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_10.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_11.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_12.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_13.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_14.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_15.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_16.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_17.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_18.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_19.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_2.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_20.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_3.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_4.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_5.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_6.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_7.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_8.csv',\n",
       " '/home/com_2/workspace/pig_dataset/test/20230928_9.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/com_2/workspace/pig_dataset/test/*'\n",
    "file_list = glob.glob(path)\n",
    "files = sorted([file for file in file_list if file.endswith('.csv')])\n",
    "print(len(files))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    n = data.index[0]\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "\n",
    "        # 학습 데이터셋 다음을 label로 (len(_x) + 1)\n",
    "        _y = data.loc[n+seq_length]['label']\n",
    "        n += 1\n",
    "\n",
    "        # # 학습 데이터셋 마지막을 label로 (len(_x))\n",
    "        # _y = data.loc[n+seq_length -1]['label']\n",
    "        # n += 1\n",
    "\n",
    "        x.append(_x.drop(columns=['label']))\n",
    "        y.append([_y])\n",
    "    \n",
    "\n",
    "    return np.array(x),np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, data_x, data_y):\n",
    "    self.data_x = data_x\n",
    "    self.data_y = data_y\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data_y.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = torch.from_numpy(self.data_x[idx])\n",
    "    y = torch.from_numpy(self.data_y[idx])\n",
    "    return x,y\n",
    "  \n",
    "  def get_labels(self):\n",
    "    return list(train_y_.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "n_joints = 1\n",
    "n_categories = 1\n",
    "n_layer = 3\n",
    "batch_size = 512\n",
    "num_epochs = 150\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, n_joints, n_hidden, n_categories, n_layer):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=1440, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=1440, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(64, n_hidden, num_layers=n_layer, batch_first=True, bidirectional=True)\n",
    "        # self.lstm = nn.LSTM(64, n_hidden, num_layers=n_layer, batch_first=True)\n",
    "        \n",
    "        # FC layer\n",
    "        self.fc = nn.Linear(n_hidden*2, n_categories)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # 입력 데이터의 차원 변경\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # LSTM을 위해 차원 순서 변경\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # 마지막 시간 스텝의 결과만 사용\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(1440,), stride=(1,))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(1440,), stride=(1,))\n",
       "  (relu2): ReLU()\n",
       "  (lstm): LSTM(64, 64, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '/home/com_2/workspace/yjshin/capstone/result_lstm/1013_230026_crnn_gt_1440_1440/100.pt'\n",
    "file_name = dir.split('/')[-2] + '_' + dir.split('/')[-1]\n",
    "\n",
    "seq_length = 2879\n",
    "\n",
    "model = CRNN(n_joints, n_hidden, n_categories, n_layer)\n",
    "model.load_state_dict(torch.load(dir))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_pred = np.array([])\n",
    "        y_valid = np.array([])\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "            labels = torch.squeeze(labels)\n",
    "            # outputs = model(inputs).squeeze()\n",
    "            # print(outputs)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            # predicted = torch.tensor([1 if x > 0.1 else 0 for x in outputs]).squeeze()\n",
    "            predicted = torch.round(outputs).squeeze()\n",
    "            # predicted = outputs.squeeze()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            # y_pred.append(predicted)\n",
    "            # y_valid.append(labels)\n",
    "\n",
    "            y_pred = np.concatenate([y_pred, np.array(predicted.cpu())])\n",
    "            y_valid = np.concatenate([y_valid, np.array(labels.cpu())])\n",
    "            \n",
    "            # y_pred = np.concatenate([y_pred, np.array(predicted)])\n",
    "            # y_valid = np.concatenate([y_valid, np.array(labels.cpu())])\n",
    "            total += labels.size(0)\n",
    "            \n",
    "    return y_valid, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(pig_data, y_valid, y_pred, file, folder_name, seq_length):\n",
    "\n",
    "        # gt = pig_data.index[pig_data['label'] == 1].tolist()[-1]\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        ax1 = fig.add_subplot()\n",
    "\n",
    "        window_size = 1440\n",
    "        moving_average = []\n",
    "        file_name = file.split('/')[-1][:-4]\n",
    "        for i in range(len(pig_data['ear_state'])-window_size):\n",
    "                moving_average.append(sum(pig_data['ear_state'][i:i+window_size])/window_size)\n",
    "\n",
    "        window_size_2 = 720*2\n",
    "        db_moving_average = []\n",
    "        for i in range(len(moving_average)-window_size_2):\n",
    "                db_moving_average.append((sum(moving_average[i:i+window_size_2]))/window_size_2)\n",
    "        c1 = ax1.plot(pig_data['ear_state'].index[seq_length+1:], y_valid, label='gt')\n",
    "        c2 = ax1.plot(pig_data['ear_state'].index[seq_length+1:], y_pred, label='pred')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        # c3 = ax2.scatter(gt, db_moving_average[gt-(window_size+window_size_2)], c='r', zorder=3)\n",
    "        c4 = ax2.plot(pig_data['ear_state'].index[window_size+window_size_2:], db_moving_average, color='gray', label='1440-720-MA')\n",
    "\n",
    "        c = c1 + c2 + c4\n",
    "        ax1.legend(c, ['gt', 'pred', '1440-1440-MA'], loc='upper right')\n",
    "        plt.title(file_name)\n",
    "        \n",
    "        directory = f'/home/com_2/workspace/out_graph/{folder_name}'\n",
    "        if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        plt.savefig(f'{directory}/{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_graph(pig_data, y_valid, y_pred, file, folder_name, seq_length):\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        ax1 = fig.add_subplot()\n",
    "\n",
    "        file_name = file.split('/')[-1][:-4]\n",
    "                \n",
    "        window_size = 1440\n",
    "        window_size_2 = 720*2\n",
    "        \n",
    "        \n",
    "        ma_gt = np.convolve(y_valid, np.ones(window_size)/window_size, mode='valid')\n",
    "        \n",
    "        ma_pred = np.convolve(y_pred, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "        ma_pig = pig_data[\"ear_state\"].rolling(window=window_size).mean()\n",
    "        ma_pig = ma_pig.dropna()\n",
    "        \n",
    "        db_ma_pig = ma_pig.rolling(window=window_size_2).mean()\n",
    "        db_ma_pig = db_ma_pig.dropna()\n",
    "        \n",
    "\n",
    "        c1 = ax1.plot(pig_data['ear_state'].index[seq_length+window_size:], ma_gt, label='gt')\n",
    "        c2 = ax1.plot(pig_data['ear_state'].index[seq_length+window_size:], ma_pred, label='pred')\n",
    "        c3 = ax1.axhline(0.1, color='green', linestyle='--', linewidth=1)\n",
    "        \n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        c4 = ax2.plot(pig_data['ear_state'].index[window_size+window_size_2-2:], db_ma_pig, color='gray', label='1440-720-MA')\n",
    "\n",
    "        c = c1 + c2 + c4\n",
    "        ax1.legend(c, ['gt', 'pred', '1440-1440-MA'], loc='upper right')\n",
    "        plt.title(file_name)\n",
    "        \n",
    "        directory = f'/home/com_2/workspace/out_graph/label_ma/{folder_name}_label_ma'\n",
    "        if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        plt.savefig(f'{directory}/{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_graph2(pig_data, y_valid, y_pred, file, folder_name, seq_length):\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        ax1 = fig.add_subplot()\n",
    "\n",
    "        file_name = file.split('/')[-1][:-4]\n",
    "                \n",
    "        window_size = 1440\n",
    "        window_size_2 = 720*2\n",
    "        \n",
    "        \n",
    "        ma_gt = np.convolve(y_valid, np.ones(window_size)/window_size, mode='valid')\n",
    "        \n",
    "        ma_pred = np.convolve(y_pred, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "        ma_pig = pig_data[\"ear_state\"].rolling(window=window_size).mean()\n",
    "        ma_pig = ma_pig.dropna()\n",
    "        \n",
    "        db_ma_pig = ma_pig.rolling(window=window_size_2).mean()\n",
    "        db_ma_pig = db_ma_pig.dropna()\n",
    "        \n",
    "        c1 = ax1.plot(pig_data['ear_state'].index[seq_length+1:],y_valid, label='gt')\n",
    "\n",
    "        # c1 = ax1.plot(pig_data['ear_state'].index[seq_length+window_size:], ma_gt, label='gt')\n",
    "        c2 = ax1.plot(pig_data['ear_state'].index[seq_length+window_size:], ma_pred, label='pred')\n",
    "        c3 = ax1.axhline(0.1, color='green', linestyle='--', linewidth=1)\n",
    "        \n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        c4 = ax2.plot(pig_data['ear_state'].index[window_size+window_size_2-2:], db_ma_pig, color='gray', label='1440-720-MA')\n",
    "\n",
    "        c = c1 + c2 + c4\n",
    "        ax1.legend(c, ['gt', 'pred', '1440-1440-MA'], loc='upper right')\n",
    "        plt.title(file_name)\n",
    "        \n",
    "        directory = f'/home/com_2/workspace/out_graph/label_ma/{folder_name}_label_ma2'\n",
    "        if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        plt.savefig(f'{directory}/{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016_151458_1013_230026_crnn_gt_1440_1440_100.pt\n",
      "/home/com_2/workspace/pig_dataset/test/20230504_14.csv\n",
      "/home/com_2/workspace/pig_dataset/test/20230504_18.csv\n",
      "/home/com_2/workspace/pig_dataset/test/20230504_7.csv\n"
     ]
    }
   ],
   "source": [
    "folder_name = f'{datetime.now().strftime(\"%m%d_%H%M%S\")}_{file_name}'\n",
    "print(folder_name)\n",
    "for i, file in enumerate(files):\n",
    "    print(file)\n",
    "    pig_data = pd.read_csv(file)\n",
    "    pig_data = pig_data.drop(columns=['Date_time'])\n",
    "    x, y = sliding_windows(pig_data, seq_length)\n",
    "    test_dataset = CustomDataset(x, y)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=False)\n",
    "    y_valid, y_pred = test(model, test_loader)\n",
    "    graph(pig_data, y_valid, y_pred, file, folder_name, seq_length)\n",
    "    # ma_graph2(pig_data, y_valid, y_pred, file, folder_name, seq_length)\n",
    "    # ma_graph(pig_data, y_valid, y_pred, file, folder_name, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
